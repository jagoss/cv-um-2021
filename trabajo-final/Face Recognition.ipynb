{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Face Recognition.ipynb","provenance":[],"collapsed_sections":["h_pUK1Nhz1eE"]}},"cells":[{"cell_type":"code","metadata":{"id":"z-JwzsV3x8Yr"},"source":["#@title \n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZdQGl5py5EL"},"source":["%cd /content/drive/MyDrive/computer-vision-um/cv-um-2021/trabajo-final/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYz6RPmCyGdX"},"source":["\n","# Ejercicio 2.2: Face Recognition\n","\n","Tal como se explica en la letra del obligatorio final en este ejercicio es necesario implementar una solucion para reconocimiento de facial. Se proveen datos de entrenamiento y es necesario entrenar un clasificador para hacer el reconocimiento. Todo el código necesario para comenzar a trabajar está provisto en este notebook.\n","\n","\n","\\**En los ejercicios del trabajo final es posible utilizar funciones de librerias existentes o código sacado de internet. Siempre y cuando **no se usen para resolver explicitamente lo que pide el ejercicio** y al código sacado de interenet le agreguen el link en comentarios de donde fue sacado ese código.*\n","\n"]},{"cell_type":"code","metadata":{"id":"RELk0NVIptA4"},"source":["import cv2 \n","import numpy as np\n","import os\n","import sklearn \n","import sklearn.neighbors\n","import matplotlib.pyplot as plt\n","import pickle\n","import sys\n","import scipy.io"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3JXhv8jYptA8"},"source":["\n","\n","### Cargar Datos de Entrenamiento y Validación\n"]},{"cell_type":"code","metadata":{"id":"UrRc4YGHptA9"},"source":["data_dir='./data'\n","face_recognition_dir = os.path.join(data_dir, 'face_recognition')\n","training_data_file = os.path.join(face_recognition_dir, 'face_recognition_data_tr.mat')\n","validation_data_file = os.path.join(face_recognition_dir, 'face_recognition_data_va.mat')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3dmVXAFptA-"},"source":["training_data_mat = scipy.io.loadmat(training_data_file)\n","validation_data_mat = scipy.io.loadmat(validation_data_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NptLYA8sptA-"},"source":["training_data=training_data_mat['tr_img_sample']\n","validation_data = validation_data_mat['va_img_sample']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_pUK1Nhz1eE"},"source":["### Esqueleto de funciones para extracción de Features"]},{"cell_type":"code","metadata":{"id":"qj9cSW11zzQL"},"source":["class FeatureExtractors(Enum):\n","\t\tMiniImage = 1\n","\t\tHOG = 2\n","\t\tLBP = 3\n","\n","def extract_features(method, img):\n","\t'''Switch between Feature extraction Methods'''\n","\n","\timage_representation = []\n","\n","\tif method == FeatureExtractors.MiniImage:\n","\t\timage_representation = extract_mini_image_features(img)\n","\telif method == FeatureExtractors.HOG:\n","\t\timage_representation = extract_hog_features(img)\n","\telif method == FeatureExtractors.LBP:\n","\t\timage_representation = extract_lbp_features(img)\t\n","\t\n","\treturn image_representation\n","\n","def extract_mini_image_features(img,resize_size=(64,64)):\n","\tresized_image = cv2.resize(img,resize_size)\n","\timage_representation = resized_image.reshape(resize_size[0]*resize_size[1])\n","\treturn image_representation\n","  \n","def extract_lbp_features(img):\n","  return []\n","\n","def extract_hog_features(img):\n","  return []\n","\n","\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KHCBXMJAptA_"},"source":["### Armar los datos de entrenamiento y sus etiquetas"]},{"cell_type":"code","metadata":{"id":"VJI80Tk8ptA_"},"source":["training_images = []\n","training_labels = []\n","for training_image in training_data:\n","    image = (training_image[0]/255)\n","    label = training_image[2]\n","    training_images.append(image.reshape(64*64))\n","    training_labels.append(label.reshape(1))\n","\n","training_images = np.asarray(training_images)\n","training_labels = np.asarray(training_labels)\n","training_labels = training_labels.reshape(training_labels.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OxXEG1AyptBA"},"source":["training_labels.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PIhGAwPrptBB"},"source":["### Construir datos de validación y sus etiquetas\n"]},{"cell_type":"code","metadata":{"id":"0HSgLxEtptBC"},"source":["validation_images = []\n","validation_labels = []\n","validation_names = []\n","for validation_image in validation_data:\n","    image = (validation_image[0]/255)\n","    label = validation_image[2] \n","    name = validation_image[1][0].split('.')[0]\n","    validation_images.append(image.reshape(64*64))\n","    validation_labels.append(label.reshape(1))\n","    validation_names.append(name)\n","\n","validation_images = np.asarray(validation_images)\n","validation_labels = np.asarray(validation_labels)\n","validation_labels = validation_labels.reshape(validation_labels.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5L0nJy0aptBC"},"source":["knn_classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3,algorithm='brute')\n","knn_classifier.fit(training_images,training_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBAS3HxCptBD"},"source":["#### Guardar Modelo Entrenado"]},{"cell_type":"code","metadata":{"id":"GrdVFBTBptBD"},"source":["pickle.dump(knn_classifier,open('./face_recogition', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QyAHVHKptBE"},"source":["#### Cargar modelo"]},{"cell_type":"code","metadata":{"id":"cjzBPFu3ptBE"},"source":["classifier = pickle.load(open('./face_recogition','rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4N071KXqptBE"},"source":["### Clasificar los datos de validación\n"]},{"cell_type":"code","metadata":{"id":"BZiwMoeqptBE"},"source":["labels = classifier.predict(validation_images)\n","## Get score for each sliding window patch\n","scores = classifier.predict_proba(validation_images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHfEzPlcptBF"},"source":["###  Evaluar modelo de Reconocimento"]},{"cell_type":"code","metadata":{"id":"i5opEc6JptBF"},"source":["acc = np.mean(labels==validation_labels)*100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrREv9-0ptBF"},"source":["print('The accuracy of face recognition is:%.2f \\n' % acc)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g5_H9zrDptBF"},"source":["### Visualize Recognition ###"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"SSW6M4WpptBG"},"source":["indexes = [13,50,77,18,110] # You can use Random Sample\n","for index in indexes:\n","    predicted_label=labels[index]\n","    real_label = validation_labels[index]\n","\n","    pred_name = validation_names[np.nonzero(validation_labels==predicted_label)[0][0]]\n","    real_name = validation_names[np.nonzero(validation_labels==real_label)[0][0]]\n","    if real_label==predicted_label:\n","        text='TRUE'\n","        color='g'\n","    else:\n","        text='FALSE'\n","        color='r'\n","    font = {'family': 'serif',\n","            'color':  color,\n","            'weight': 'normal',\n","            'size': 16,\n","            }    \n","    plt.imshow(validation_images[index].reshape(64,64), cmap='gray')\n","    plt.axis('off')\n","    plt.title(text, fontdict=font)\n","    sub_font = {'family': 'serif',\n","            'weight': 'normal',\n","            'size': 14,\n","            }    \n","    plt.text(0.5, 75, 'Pred: {} \\nReal: {}'.format(pred_name[:-5],real_name[:-5]), fontdict=sub_font)\n","\n","    plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTdCXcw5zE5k"},"source":[""],"execution_count":null,"outputs":[]}]}