{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Face Detection.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"F56hbYscHDq1"},"source":["#@title \n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImhJDxNxw7Uk"},"source":["%cd /content/drive/MyDrive/computer-vision-um/cv-um-2021/trabajo-final/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Es7fW58WFzaQ"},"source":["\n","# Ejercicio 2.1: Face Detection\n","\n","Tal como se explica en la letra del obligatorio final en este ejercicio es necesario implementar desde cero una solucion para detección de caras. Se proveen datos de entrenamiento y es necesario implementar su propio algoritmo de sliding window para entrenar un clasificador. Todo el código necesario para comenzar a trabajar está provisto en este notebook.\n","\n","\n","\\**En los ejercicios del trabajo final es posible utilizar funciones de librerias existentes o código sacado de internet. Siempre y cuando **no se usen para resolver explicitamente lo que pide el ejercicio** y al código sacado de interenet le agreguen el link en comentarios de donde fue sacado ese código.*\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iiKqFLGiG_GF"},"source":["##### Imports necesarios"]},{"cell_type":"code","metadata":{"id":"1R0bQDoWFlN8"},"source":["import cv2 \n","import numpy as np\n","from glob import glob\n","from enum import Enum\n","import os\n","import sklearn \n","import sklearn.neighbors\n","import matplotlib.pyplot as plt\n","import pickle\n","from evaluation import evaluate_detector, precision_and_recall, interpolated_average_precision\n","import sys\n","from image_utils import non_max_suppression\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykAG8DVaHTBW"},"source":["### Funciones Provistas\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dL0t1grWIgR_"},"source":["#### Feature Extractors \n","\n","Para resolver el ejercicio van a tener que implementar las funciones `extract_hog_features` y `extract_lbp_features`"]},{"cell_type":"code","metadata":{"id":"JkDuSqQJIEUN"},"source":["class FeatureExtractors(Enum):\n","\t\tMiniImage = 1\n","\t\tHOG = 2\n","\t\tLBP = 3\n","\n","def extract_features(method, img):\n","\t'''Switch between Feature extraction Methods'''\n","\n","\timage_representation = []\n","\n","\tif method == FeatureExtractors.MiniImage:\n","\t\timage_representation = extract_mini_image_features(img)\n","\telif method == FeatureExtractors.HOG:\n","\t\timage_representation = extract_hog_features(img)\n","\telif method == FeatureExtractors.LBP:\n","\t\timage_representation = extract_lbp_features(img)\t\n","\t\n","\treturn image_representation\n","\n","def extract_mini_image_features(img,resize_size=(64,64)):\n","\tresized_image = cv2.resize(img,resize_size)\n","\timage_representation = resized_image.reshape(resize_size[0]*resize_size[1])\n","\treturn image_representation\n","  \n","def extract_lbp_features(img):\n","  return []\n","\n","def extract_hog_features(img):\n","  return []\n","\n","\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6lPvlmEnIs2n"},"source":["#### Data loader"]},{"cell_type":"code","metadata":{"id":"WX-Tpj9JI1qt"},"source":["def load_training_data(training_positive_dir,trainign_negative_dir, feature_extractor=FeatureExtractors.MiniImage):\n","    ''' Function for loading loading training data from positive and negative examples\n","    '''\n","    positive_img_files = sorted(glob(training_positive_dir + '/*'))\n","    negative_img_files = sorted(glob(trainign_negative_dir + '/*'))\n","    #comment these lines for loading all data\n","    #change these lines for increasing the amount of data\n","    positive_img_files = positive_img_files[:100]\n","    negative_img_files = negative_img_files[:200]\n","\n","    training_data = []\n","    training_labels = []\n","    \n","    print('##Loading {} positive face images'.format(len(positive_img_files)))\n","    for img in positive_img_files:\n","        image = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n","        image_representation = extract_features(feature_extractor,image)\n","        training_data.append(image_representation)\n","        training_labels.append(1)\n","    \n","    print('##Loading {} negative face images'.format(len(negative_img_files)))\n","    for img in negative_img_files:\n","        image = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n","        image_representation = extract_features(feature_extractor,image)\n","        training_data.append(image_representation)\n","        training_labels.append(0)   \n","    \n","    training_data = np.asarray(training_data)\n","    training_labels = np.asarray(training_labels)\n","    return training_data, training_labels\n","\n","def load_validation_data(validation_data_dir):\n","\n","    validation_image_files = sorted(glob(validation_data_dir + '/*'))\n","    val_images = []\n","    for img_file in validation_image_files:\n","        image = cv2.imread(img_file,cv2.IMREAD_COLOR)\n","        val_images.append(image)\n","\n","    return val_images "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rqb_HSDvJL9m"},"source":["#### Sliding Window\n"]},{"cell_type":"code","metadata":{"id":"Jf1Ic0xYJghW"},"source":["def sliding_window(image, window_size, scale, stride):\n","    [image_rows, image_cols] = image.shape;\n","    window_rows = window_size[0];\n","    window_cols = window_size[1];\n","\n","    patches = np.zeros((window_rows, window_cols,5));\n","    bbox_locations = np.zeros((5,4))\n","    r = np.random.randint(0,image_rows-window_rows,5); # Sample top left position\n","    c = np.random.randint(0,image_cols-window_cols,5);\n","    for i in range(0,5):\n","        patches[:,:,i] = image[r[i]:r[i]+window_rows, c[i]:c[i]+window_cols];\n","        bbox_locations[i,:] = [r[i],c[i],window_rows,window_cols]; # top-left y,x, height, width\n","\n","\n","    return patches, bbox_locations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AvgD3gp8LK2l"},"source":["##### Metodos Auxiliares\n"]},{"cell_type":"code","metadata":{"id":"A7dqYztRLcpg"},"source":["def show_image_with_bbox(image,bboxes,draw_GT=True):\n","    GT = [82,91,166,175]\n","    if draw_GT:\n","        cv2.rectangle(image, (GT[0],GT[1]), (GT[2],GT[3]), (0, 0, 255), 2)\n","\n","    for bbox in bboxes:\n","        if len(bbox) == 4:   \n","            top_left = (int(bbox[0]),int(bbox[1]))\n","            bottom_right = (int(bbox[0])+ int(bbox[2]),int(bbox[1])+int(bbox[3]))\n","            cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)\n","\n","    plt.imshow(image[...,::-1])\n","    plt.axis('off')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PZ3ZbWKKFlOD"},"source":["### Ubicación de los datos ###"]},{"cell_type":"code","metadata":{"id":"z-zVz-OIFlOF"},"source":["data_dir='./data'\n","face_detection_dir = os.path.join(data_dir, 'face_detection')\n","training_faces_dir = os.path.join(face_detection_dir,'cropped_faces')\n","negative_examples_training_dir = os.path.join(face_detection_dir,'non_faces_images','neg_cropped_img')\n","validation_faces_dir = os.path.join(face_detection_dir,'val_face_detection_images')\n","validation_raw_faces_dir = os.path.join(face_detection_dir,'val_raw_images')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cU7x6hD5LUC7"},"source":["## Entrenar Modelo y Face Detection\n"]},{"cell_type":"markdown","metadata":{"id":"fuo0icz8FlOG"},"source":["### Cargar Datos de Entrenamiento ###"]},{"cell_type":"code","metadata":{"id":"DtE_MyFWFlOH"},"source":["#Modify data_loader.py to load more training data\n","training_data, trainig_labels = load_training_data(training_faces_dir,negative_examples_training_dir, FeatureExtractors.MiniImage)\n","# You can save traninig_data and labels on nunmpy files to avoid processing data every time. "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VE3nYFzmFlOI"},"source":["### Load Validation Data ###"]},{"cell_type":"code","metadata":{"id":"4N00jneNFlOI"},"source":["validation_data = load_validation_data(validation_faces_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7poHeRhFlOI"},"source":["### Entrenar un clasificador utilizando los datos de entrenamiento ## \n","1. Una vez los datos de entrenamiento han sido cargados es necesario entrenar su propio clasificador \n","2. Como solución inicial se utiliza un clasificador KNN pero para tener mejores resultados es posible entrenar un SVM. Se puede utilizar el [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) de sklearn a modo de ejemplo\n","3. Entrenar su clasificador y guardarlo en el archivo `face_detector`"]},{"cell_type":"code","metadata":{"id":"oSpg1nVpFlOK"},"source":["knn_classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIQwPwWQFlOM"},"source":["knn_classifier.fit(training_data,trainig_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1s2k3ufmFlOQ"},"source":["#### Guardar el modelo entrenado ##"]},{"cell_type":"code","metadata":{"id":"2fRvvaBOFlOR"},"source":["pickle.dump(knn_classifier,open('./face_detector', 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xWUPszrDFlOS"},"source":["#### Cargar el Modelo entrenado "]},{"cell_type":"code","metadata":{"id":"KVizcW8qFlOS"},"source":["classifier = pickle.load(open('./face_detector','rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4JLCn_hOFlOS"},"source":["### Do the sliding window and Visualize Results ###\n","1. In this part you need to perform the sliding window and score the probabilty of each patch of being a face and select the highest probability patches. \n","    1a. Program you own sliding window in 'img_utils' file.\n","    1b. Extract Features and classify each patch with your own classifier. \n","2. Do non-max suppression to select the target face patch with best probability (This is provided in 'img_utils')\n","3. Visualize Detection with Ground Throuth Bounding Box ('Code for Visualization is Provided')"]},{"cell_type":"code","metadata":{"id":"8ceFJnT3FlOT"},"source":["window_size = [64, 64]\n","predictions = []\n","threshold_p = 0.5\n","overlap_threshold = 0.5\n","validation_data = load_validation_data(validation_faces_dir)\n","for img in validation_data:\n","    gray_image = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n","    patches, bbox_locations = sliding_window(gray_image,window_size,1,32)\n","\n","    ## You need to extract features for every patch (same features you used for training the classifier)\n","    patches_feature_representation = []\n","    for i in range(patches.shape[2]):\n","        patch_representation = extract_features(FeatureExtractors.MiniImage, patches[:,:,i])\n","        patches_feature_representation.append(patch_representation)\n","    patches_feature_representation = np.asarray(patches_feature_representation)\n","    ## Get prediction label for each sliding window patch\n","    labels = classifier.predict(patches_feature_representation)\n","    ## Get score for each sliding window patch\n","    scores = classifier.predict_proba(patches_feature_representation)\n","    ## Positive Face Probabilities\n","    face_probabilities = scores[:,1]\n","    face_bboxes = bbox_locations[face_probabilities>threshold_p]\n","    face_bboxes_probabilites = face_probabilities[face_probabilities>threshold_p]\n","    # Do non max suppression and select strongest probability box\n","    [selected_bbox, selected_score] = non_max_suppression(face_bboxes,face_bboxes_probabilites,0.3)\n","    show_image_with_bbox(img, selected_bbox)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTKhHhrcFlOV"},"source":["### Evaluate Detector ###"]},{"cell_type":"code","metadata":{"id":"N_uqzQvfFlOW"},"source":["total_true_positives = []\n","total_real_positives = []\n","total_positive_predictions = []\n","window_size = [64, 64]\n","for subject_folder in sorted(glob(validation_raw_faces_dir + '/*')):\n","    for img in sorted(glob(subject_folder + '/*.jpg')):\n","        gray_image = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n","        patches, bbox_locations = sliding_window(gray_image,window_size,1,32)\n","        ## You need to extract features for every patch (same features you used for training the classifier)\n","        patches_feature_representation = []\n","        for i in range(patches.shape[2]):\n","            patch_representation = extract_features(FeatureExtractors.MiniImage, patches[:,:,i])\n","            patches_feature_representation.append(patch_representation)\n","        patches_feature_representation = np.asarray(patches_feature_representation)\n","        ## Get score for each sliding window patch\n","        scores = classifier.predict_proba(patches_feature_representation)\n","        ## Positive Face Probabilities\n","        face_probabilities = scores[:,1]\n","        #[labels, acc, prob] = predict([],patches_feature_representation, clasifier)\n","        ## Positive Face Probabilities\n","        #face_probabilities = np.asarray(prob)\n","        #face_probabilities = face_probabilities.T[0]\n","        \n","        [ detected_true_positives, image_real_positives, detected_faces ] = evaluate_detector( bbox_locations, face_probabilities);\n","        total_true_positives.append(detected_true_positives)\n","        total_real_positives.append(image_real_positives)\n","        total_positive_predictions.append(detected_faces)\n","        \n","total_true_positives = np.asarray(total_true_positives)\n","total_real_positives = np.asarray(total_real_positives)\n","total_positive_predictions = np.asarray(total_positive_predictions)\n","        \n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LwPNwJ3HxfwX"},"source":["### Evaluation Results "]},{"cell_type":"code","metadata":{"id":"NhxvUzlqFlOZ"},"source":["precision, recall = precision_and_recall(total_true_positives, total_real_positives,total_positive_predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVy7HDnxFlOa"},"source":["plt.plot(recall, precision)\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.xlim(0,1.1)\n","plt.ylim(0,1.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yw74Qp4VFlOc"},"source":["ap = interpolated_average_precision(recall,precision)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBVw-MBqFlOc"},"source":["print('Detection Average Precision is {}'.format(ap))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6gF8-dcyysa"},"source":[""],"execution_count":null,"outputs":[]}]}